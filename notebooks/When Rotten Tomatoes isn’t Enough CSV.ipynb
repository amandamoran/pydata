{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Rotten Tomatoes Isn't Enough: Twitter Sentiment Analysis with DSE\n",
    "------\n",
    "<img src=\"images/allLogos.png\" width=\"250\" height=\"250\">\n",
    "#### A demo using DataStax Enterprise Analytics, Apache Cassandra, Apache Spark, Python, Jupyter Notebooks, Twitter tweets, pattern, and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things To Setup\n",
    "#### Please work through the ***Installation of DSE and Juypter Notebook*** for setup instructions\n",
    "\n",
    "\n",
    "##### On your free time try to get the Twitter Dev API up and running. Utilize the other notebooks for this. This example will use CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some environment variables to find dse verision of pyspark. Edit these varibles with your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkzip = \"<>/cassandra/dse-6.0.4/resources/spark/python/lib/pyspark.zip\"\n",
    "py4jzip = \"\"<>/cassandra/dse-6.0.4/resources/spark/python/lib/py4j-0.10.4-src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to be able to find pyspark libaries\n",
    "import sys\n",
    "sys.path.append(pysparkzip)\n",
    "sys.path.append(py4jzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python packages -- all are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pattern.en import sentiment, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', -1)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataStax Enterprise Analytics\n",
    "<img src=\"images/datastaxlogo.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables and Loading Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DSE Analytics Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demo Keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS demo1 \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('demo1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Movie Title variable --Change this to search for different movies!\n",
    "##### Choices are: MamaMia2, FirstMan, AStarIsBorn, and MissionImpossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTitle = \"??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveNegative = [\"pos\", \"sad\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create two tables in Cassandra for the movie title. One of negative tweets and one for positive tweets. Twitter returns a lot of information with each call but for this demo we will just utilize the twitter id (as our Primary key as it is unique) and the actual tweet. \n",
    "#### Is using twitter id the right value to distriubte by? Consider your data model when choosing your primary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in positiveNegative: \n",
    "    \n",
    "    query = \"CREATE TABLE IF NOT EXISTS movie_tweets_%s_%s (twitterid bigint, tweet text, PRIMARY KEY (twitterid))\" % (movieTitle, emotion)\n",
    "    print query\n",
    "    session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Twitter Tweets\n",
    "#### Pulled from twitter and stored in CSV file\n",
    "<img src=\"images/twitterlogo.png\" width=\"100\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Negative Tweets from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'data/' + movieTitle + '_sad.csv'\n",
    "input_file = open(fileName, 'r')\n",
    "for line in input_file:\n",
    "    tweets = line.split(',')\n",
    "    query = \"INSERT INTO movie_tweets_%s_sad (twitterid, tweet)\" % (movieTitle)\n",
    "    query = query + \" VALUES (%s, %s)\"\n",
    "    session.execute(query, (int(tweets[0]), tweets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Postive Tweets from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName1 = 'data/' + movieTitle + '_pos.csv'\n",
    "input_file1 = open(fileName1, 'r')\n",
    "for line in input_file1:\n",
    "    tweets = line.split(',')\n",
    "    query = \"INSERT INTO movie_tweets_%s_pos (twitterid, tweet)\" % (movieTitle)\n",
    "    query = query + \" VALUES (%s, %s)\"\n",
    "    session.execute(query, (int(tweets[0]), tweets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a select * on each table and verify that the tweets have been inserted into each Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for emotion in positiveNegative:\n",
    "    print emotion\n",
    "    query = 'SELECT * FROM movie_tweets_%s_%s limit 10' % (movieTitle, emotion)\n",
    "    rows = session.execute(query)\n",
    "    for user_row in rows:\n",
    "        print (user_row.twitterid, user_row.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSE Analytics with Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally time for Apache Spark! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to Cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "\n",
    "tableNamePos = \"movie_tweets_%s_pos\" % (movieTitle.lower())\n",
    "tableNameSad = \"movie_tweets_%s_sad\" % (movieTitle.lower())\n",
    "tablepos = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNamePos, keyspace=\"demo1\").load()\n",
    "tablesad = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNameSad, keyspace=\"demo1\").load()\n",
    "\n",
    "print \"Postive Table Count: \"\n",
    "print tablepos.count()\n",
    "print \"Negative Table Count: \"\n",
    "print tablesad.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Tokenizer to break up the sentences into indiviudals words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerPos = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedPos = tokenizerPos.transform(tablepos)\n",
    "\n",
    "dfPos = tokenizedPos.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfPos)\n",
    "\n",
    "tokenizerSad = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedSad = tokenizerSad.transform(tablesad)\n",
    "\n",
    "dfSad = tokenizedSad.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfSad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using StopWordsRemover to remove all stop words. Interesting to see, people don't use many stop words with twitter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removerPos = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedPos = removerPos.transform(dfPos)\n",
    "\n",
    "dfPosStop = removedPos.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfPosStop)\n",
    "\n",
    "removerSad = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedSad = removerSad.transform(dfSad)\n",
    "\n",
    "dfSadStop = removedSad.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfSadStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Python package Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert each Spark Dataframe to a Pandas Dataframe. This works as-is because we are working with a small dataset. For larger datasets only convert to Pandas if data can fit in memory. From there loop over each row and get the sentiment score (anything + is postive and anything - or 0 is negative). The \"positive\" function will return true if the tweet is postive. The \"assessment\" function shows which words where used to judge and the score of each word. For more info on how the scores are calcuated: https://www.clips.uantwerpen.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandaSad = dfSadStop.toPandas()\n",
    "movieScoreSad = 0\n",
    "countSad = 0\n",
    "numSadTweets = 0\n",
    "sadList = list()\n",
    "\n",
    "for index, row in pandaSad.iterrows():\n",
    "    if positive(row[\"tweetnostopwords\"], .1):\n",
    "        countSad = countSad + 1\n",
    "    scoreSad = sentiment(row['tweetnostopwords'])[0]\n",
    "    if scoreSad <= 0:\n",
    "        #print row['tweet']\n",
    "        #print sentiment(row['tweetnostopwords'])[0]\n",
    "        sadList.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScoreSad = scoreSad + movieScoreSad\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "sadTweetScores = pandas.DataFrame.from_records(sadList, columns=labels)\n",
    "\n",
    "sadTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Tweet\n",
    "#### Also adding up all the sentiment scores of all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaPos = dfPosStop.toPandas()\n",
    "movieScore = 0\n",
    "countPos = 0\n",
    "poslist = list()\n",
    "\n",
    "for index, row in pandaPos.iterrows():\n",
    "    if not positive(row[\"tweetnostopwords\"]) and sentiment(row[\"tweetnostopwords\"])[0] != 0.0:\n",
    "        countPos = countPos + 1\n",
    "    score = sentiment(row['tweetnostopwords'])[0]\n",
    "    if score > 0:\n",
    "        #print row['tweet']\n",
    "        #print sentiment(row['tweetnostopwords'])[0]\n",
    "        poslist.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScore = score + movieScore\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "postiveTweetScores = pandas.DataFrame.from_records(poslist, columns=labels)\n",
    "\n",
    "postiveTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright! Should I see this movie???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posrating = movieScore/(dfPos.count() - countPos)\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Positive Rating Average Score\", posrating)))\n",
    "\n",
    "if dfSad.count() != 0:\n",
    "    sadrating = movieScoreSad/(dfSad.count() - countSad)\n",
    "else: \n",
    "    sadrating = 0\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Negative Rating Average Score\", sadrating)))\n",
    "\n",
    "if posrating > abs(sadrating):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People Like This Movie!\")))\n",
    "elif posrating == abs(sadrating):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People are split! Take a chance!\")))\n",
    "elif posrating < abs(sadrating):\n",
    "    display(Markdown('***{}***  \\n'.format(\"People Do Not Like This Movie!\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is this answer what you were expecting? Either way, go back and take a look at "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we try this again, but removing some extra StopWords. Let's remove: \n",
    "* Movie Title\n",
    "* :)\n",
    "* :(\n",
    "* mission, impossible, star, first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using StopWordsRemover to remove list of stop words (but note will not remove other stop words!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordList = [movieTitle,\":(\",\":)\", \"mission\", \"impossible\", \"Star\", \"first\"]\n",
    "\n",
    "removerPos = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\", stopWords=stopwordList)\n",
    "removedPos = removerPos.transform(dfPos)\n",
    "\n",
    "dfPosStop = removedPos.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfPosStop)\n",
    "\n",
    "removerSad = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\", stopWords=stopwordList)\n",
    "removedSad = removerSad.transform(dfSad)\n",
    "\n",
    "dfSadStop = removedSad.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfSadStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sad Tweets: Convert to Pandas, use Pattern to get sentiment, and get the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaSad = dfSadStop.toPandas()\n",
    "movieScoreSad = 0\n",
    "countSad = 0\n",
    "numSadTweets = 0\n",
    "sadList = list()\n",
    "\n",
    "for index, row in pandaSad.iterrows():\n",
    "    if positive(row[\"tweetnostopwords\"], .1):\n",
    "        countSad = countSad + 1\n",
    "    scoreSad = sentiment(row['tweetnostopwords'])[0]\n",
    "    if scoreSad <= 0:\n",
    "        sadList.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScoreSad = scoreSad + movieScoreSad\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "sadTweetScores = pandas.DataFrame.from_records(sadList, columns=labels)\n",
    "\n",
    "sadTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Tweets: Convert to Pandas, use Pattern to get sentiment, and get the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaPos = dfPosStop.toPandas()\n",
    "movieScore = 0\n",
    "countPos = 0\n",
    "poslist = list()\n",
    "\n",
    "for index, row in pandaPos.iterrows():\n",
    "    if not positive(row[\"tweetnostopwords\"]) and sentiment(row[\"tweetnostopwords\"])[0] != 0.0:\n",
    "        countPos = countPos + 1\n",
    "    score = sentiment(row['tweetnostopwords'])[0]\n",
    "    if score > 0:\n",
    "        poslist.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScore = score + movieScore\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "postiveTweetScores = pandas.DataFrame.from_records(poslist, columns=labels)\n",
    "\n",
    "postiveTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay let's see if there was a difference! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posrating1 = movieScore/(dfPos.count() - countPos)\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Positive Rating Original Average Score\", posrating)))\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Positive Rating Average Score\", posrating1)))\n",
    "\n",
    "if dfSad.count() != 0:\n",
    "    sadrating1 = movieScoreSad/(dfSad.count() - countSad)\n",
    "else: \n",
    "    sadrating1 = 0\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Negative Rating Original Average Score\", sadrating)))\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Negative Rating Average Score\", sadrating1)))\n",
    "\n",
    "if posrating1 > abs(sadrating1):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People Like This Movie!\")))\n",
    "elif posrating1 == abs(sadrating1):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People are split! Take a chance!\")))\n",
    "elif posrating1 < abs(sadrating1):\n",
    "    display(Markdown('***{}***  \\n'.format(\"People Do Not Like This Movie!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
